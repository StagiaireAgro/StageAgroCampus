---
title: "tts_plateformes_2022_2023"
format: html
editor: visual
---

# I) Chargement des bibliothèques nécessaires

```{r,message=FALSE}

# Pour lire les fichiers CSV
library(vroom)

# Pour manipuler et détecter les chaînes de caractères
library(stringr)

# Pour gérer les accents et normaliser les chaînes
library(stringi)
library(fs)

# Le tidyverse est un méta-package qui regroupe plusieurs packages R
# utiles pour la manipulation, la transformation, et la visualisation de données :
# - ggplot2 : pour la visualisation
# - dplyr : pour la manipulation de données (filtrer, trier, grouper...)
# - tidyr : pour le reshaping (pivot_longer, pivot_wider, etc.)
# - readr : pour lire des fichiers plats (CSV, TSV...)
# - purrr : pour la programmation fonctionnelle (map, etc.)
# - tibble : pour manipuler des data frames modernes
# - stringr : pour manipuler des chaînes de caractères
# - forcats : pour manipuler des facteurs

library(tidyverse)

library(purrr)

```

# II) Documentation des variables d'intérêts pour le calcul du prix au kilogramme

| Variable                    | Définition |
|-----------------------------|------------|
| orderProductPrice           |            |
| orderQuantity               |            |
| mois                        |  Mois      |
| annee                       |  Année     |
| productName                 |            |
| productIsOrganic            |            |
| productConditioningQuantity |            |
| productConditioningUnit     |            |
| distributionZipCode         |            |
| plateforme                  |            |

# III) Importation des fichiers

```{r,message=FALSE}
dossier_racine <- "data/2022-2023"
fichiers <- dir_ls(path = dossier_racine, recurse = TRUE, glob = "*.csv")
noms_fichiers <- path_ext_remove(path_file(fichiers))
datasets <- lapply(fichiers, function(file) vroom(file))
names(datasets) <- noms_fichiers
View(datasets)
```

# IV) Harmonisation des noms de colonnes de toutes les plateformes

```{r}
# On ajoute la colonne pour le bio 

datasets$ruche_oui_2022$productIsOrganic <- NA
datasets$ruche_oui_2023$productIsOrganic <- NA
```

```{r}
# Colonne de cagette à garder 
colonne_cagette_a_garder <- c(
  "orderProductPrice", "orderQuantity", "mois", "annee", "productName", 
  "productIsOrganic", "productConditioningQuantity", "productConditioningUnit", 
  "distributionZipCode")
indices_cagette <- startsWith(names(datasets), "cagette")

datasets[indices_cagette] <- lapply(datasets[indices_cagette], function(x) {
  select(x, any_of(colonne_cagette_a_garder))
})


# Colonne de ruche qui dit oui à garder 
colonne_ruche_a_garder <- c(
  "price_ttc_item","nb_item","mois","annee", "product_name","productIsOrganic",
  "weight_raw_item", "quantityunit", "hive_zipcode")

indices_ruche <- startsWith(names(datasets), "ruche")

datasets[indices_ruche] <- lapply(datasets[indices_ruche], function(x) {
  select(x, any_of(colonne_ruche_a_garder))
})

# Colonne de socleo qui dit oui à garder 
colonne_socleo_a_garder <- c(
  "value", "quantite_com","mois","annee","name","is_organic","quantite_cond",
  "unite_conditionnement", "code_postal")

indices_socleo <- startsWith(names(datasets), "socleo")

datasets[indices_socleo] <- lapply(datasets[indices_socleo], function(x) {
  select(x, any_of(colonne_socleo_a_garder))
})

# Colonne de coop circuit qui dit oui à garder 
colonne_coop_circuit_a_garder <- c(
  "price", "quantite_unite","mois", "annee", "name", "is_organic", "quantite_cond",
  "conditionnement","code_postal") 

indices_coop_circuit <- startsWith(names(datasets), "coop_circuit")

datasets[indices_coop_circuit] <- lapply(datasets[indices_coop_circuit], function(x) {
  select(x, any_of(colonne_coop_circuit_a_garder))
})

# Renommer toutes les noms de colonnes des bases aux noms de celui de cagette
datasets[!indices_cagette] <- lapply(datasets[!indices_cagette], function(df) {
  df <- select(df, everything())
  colnames(df) <- colonne_cagette_a_garder
  return(df)
})

liste_datasets_final <- lapply(names(datasets), function(nom) {
  df <- datasets[[nom]]
  df$plateforme <- str_split(nom, "_")[[1]][1]
  df
})

names(liste_datasets_final) <- names(datasets)

View(liste_datasets_final)

```

# V) Fusion de tous les jeux de données sauf cagette

```{r,warning=FALSE}
liste_datasets_final_sans_cagette <- liste_datasets_final[!indices_cagette]

combinaison <- do.call(rbind, liste_datasets_final_sans_cagette)
View(combinaison)
```

# VI) Séparation des fichiers par produit

## a) Définition de la liste de produits

```{r}
# Liste des produits alimentaires à rechercher
liste_produits <- c(
  "Clémentine", "Tomate", "Carotte", "Cerise", "Chou fleur",
  "Fraise", "Kiwi", "Lait", "Oeuf", "Poireau", "Poire", "Raisin",
  "Haricot vert", "Noix", "Pomme", "Boeuf", "Porc", "Poulet",
  "Laitue", "Lentille", "Abricot", "Pomme de terre", "Oignon",
  "Courgette", "Aubergine", "Asperge", "Banane", "Poivron",
  "Jus de pomme", "Celeri branche", "Concombre", "Prune",
  "Peche", "Potiron", "Melon", "Endive", "Nectarine")

# Mise en minuscules pour correspondance plus facile
liste_produits <- str_to_lower(liste_produits)

# On supprime les tirets pour correspondance plus facile
liste_produits <- gsub("-", " ", liste_produits, ignore.case = TRUE)

# On supprime les accents pour correspondance plus facile
liste_produits <- stri_trans_general(liste_produits, "Latin-ASCII")

# On ordonne la liste des noms de produits de manière decroissante selon
# le nombre de caractere de chaque mots
ordre <- order(nchar(gsub(" ", "", liste_produits)), decreasing = TRUE)
liste_produits <- liste_produits[ordre]
```

## b) Liste contenant toutes les déclinaisons possibles pour chaque nom de produit

```{r}
# Nettoyer une chaine de caractères (-> ici liste de noms de produits)
nettoyer <- function(x) {
  x <- stri_trans_general(str_to_lower(x), "Latin-ASCII") 
  x <- str_replace_all(x, "[^a-z ]", "")
  x <- trimws(x)
  return(x)
}

# Générer des expressions régulières à partir d'un mots ou liste de mots
creer_regex <- function(mots, suffixe = "(e?s)?", collapse = ".*") {
  sapply(mots, function(terme) {
    tokens <- str_split(terme, " ")[[1]] 
    regex_tokens <- paste0(tokens, suffixe)
    paste0(regex_tokens, collapse = collapse)
  })
}
# Extraires des noms de produits toutes les declinaisons des noms de la liste de produit
trouver_declinaisons_nom_produit <- function(dataset, col_produit, ls_produit, regex) {
  # Extraction des noms uniques de produits
  noms_des_produits <- nettoyer(dataset[[col_produit]])
  noms_des_produits_uniques <- unique(noms_des_produits)
  # Extraction des déclinaisons par produit
  liste_declinaisons <- sapply(seq_along(regex), function(i) {
    extractions <- str_extract(noms_des_produits_uniques, regex[i])
    extractions[extractions == ""] <- NA
    extractions <- unique(extractions[!is.na(extractions)])
    extractions
  }, simplify = FALSE)
  # Nommer chaque élément de la liste avec le nom du produit correspondant
  names(liste_declinaisons) <- ls_produit
  return(liste_declinaisons)
}
```

```{r}
# Creer les expressions reguliere de la liste des noms de produits
regex <- creer_regex(liste_produits) 
# Declinaison obtenues de manière automatique
final_declinaisons <- trouver_declinaisons_nom_produit(
    dataset = combinaison,
    col_produit = "productName",
    ls_produit = liste_produits,
    regex = regex
  )

```

## c) Développement de la fonction split

```{r}
#  Fonction split par nom de produit
separation_fichiers <- function(data, liste_produits, liste_declinai_noms_produits) {

  #### Étape 0 : Ajout et nettoyage de la colonne `name_clean` dans `data`
  data <- data %>%
    mutate(
      name_clean = productName %>%
        str_to_lower() %>%
        stri_trans_general("Latin-ASCII") %>%
        gsub("-", " ", ., ignore.case = TRUE)
    )

  #### Étape 1 : On extrait les levels des produits
  levels_produits <- levels(as.factor(data$name_clean))

  #### Étape 2 : Création de la matrice de présence
  matrice_presence <- sapply(liste_declinai_noms_produits, function(declinaisons) {
    sapply(levels_produits, function(level) {
      any(str_detect(level, fixed(declinaisons))) * 1
    })
  })

  # Transposition pour avoir les produits en colonnes
  matrice_presence <- t(matrice_presence)

  # Calcul du nombre de correspondances pour chaque level
  nb_variantes_noms <- colSums(matrice_presence)

  # Ajouter cette ligne en bas de la matrice
  matrice_presence <- rbind(matrice_presence, nb_variantes_noms)

  #### Étape 3 : Identifier les noms qui correspondent à un seul produit
  levels_uniques <- names(nb_variantes_noms[nb_variantes_noms == 1])

  # On garde uniquement les colonnes de la matrice où une seule correspondance existe
  matrice_uniques <- matrice_presence[-nrow(matrice_presence), levels_uniques, drop = FALSE]

  #### Étape 4 : Créer un vecteur nom_produit proprement
  vecteur_nom_produit <- sapply(levels_uniques, function(level) {
    idx <- which(matrice_uniques[, level] == 1)
    if (length(idx) == 1) {
      return(liste_produits[idx])
    } else {
      return(NA)
    }
  }, USE.NAMES = TRUE)

  vecteur_nom_produit <- vecteur_nom_produit[!is.na(vecteur_nom_produit)]

  # Créer le dataframe de correspondance
  df_correspondance <- data.frame(
    name_clean = names(vecteur_nom_produit),
    nom_produit = unname(vecteur_nom_produit),
    stringsAsFactors = FALSE
  )

  #### Étape 5 : Générer data_ok en ajoutant nom_produit
  data_ok <- data %>%
    filter(name_clean %in% df_correspondance$name_clean) %>%
    left_join(df_correspondance, by = "name_clean")

  #### Étape 6 : Extraire les noms avec 0 ou plusieurs correspondances
  levels_pas_ok <- names(nb_variantes_noms[nb_variantes_noms != 1])

  matrice_pas_ok <- matrice_presence[-nrow(matrice_presence), levels_pas_ok, drop = FALSE]

  vecteur_nom_pas_ok <- sapply(levels_pas_ok, function(level) {
    idx <- which(matrice_pas_ok[, level] == 1)
    if (length(idx) == 0) {
      return(NA)
    } else {
      return(paste(liste_produits[idx], collapse = ";"))
    }
  }, USE.NAMES = TRUE)

  df_correspondance_pas_ok <- data.frame(
    name_clean = names(vecteur_nom_pas_ok),
    nom_produit = unname(vecteur_nom_pas_ok),
    stringsAsFactors = FALSE
  )

  #### Étape 7 : Générer data_pas_ok
  data_pas_ok <- data %>%
    filter(name_clean %in% df_correspondance_pas_ok$name_clean) %>%
    left_join(df_correspondance_pas_ok, by = "name_clean")

  #### Étape 8 : Identifier les lignes avec plusieurs noms dans data_pas_ok
  data_ambigus <- data_pas_ok %>%
    filter(str_detect(nom_produit, ";"))

  #### Étape 9 : Nettoyage des noms emboîtés
  data_ambigus_clean <- data_ambigus %>%
    rowwise() %>%
    mutate(
      noms_list = list(str_split(nom_produit, ";")[[1]] %>% str_trim())
    ) %>%
    mutate(
      noms_clean = list({
        noms <- noms_list
        noms[!sapply(noms, function(x) any(noms != x & str_detect(noms, fixed(x))))]
      })
    ) %>%
    mutate(
      nom_produit_new = ifelse(length(noms_clean) == 1, noms_clean[[1]], paste(noms_clean, collapse = ";"))
    ) %>%
    ungroup()

  #### Étape 10 : Extraire les lignes devenues "uniques" après nettoyage
  data_deplaces <- data_ambigus_clean %>%
    filter(!str_detect(nom_produit_new, ";")) %>%
    select(-nom_produit, -noms_list, -noms_clean) %>%
    rename(nom_produit = nom_produit_new)

  #### Étape 11 : Mettre à jour data_ok
  data_ok <- bind_rows(data_ok, data_deplaces)

  #### Étape 12 : Mettre à jour data_pas_ok sans les lignes déplacées
  data_pas_ok <- data_pas_ok %>%
    filter(!(name_clean %in% data_deplaces$name_clean))

  return(list(data_ok = data_ok, data_pas_ok = data_pas_ok))
}
```

## d) Application de la fonction split

```{r,message=FALSE,warning=FALSE}

# Test de la fonction : Fichier coop circuit 2021
system.time({ 
  resultats_2 <- separation_fichiers(
  data = combinaison,
  liste_produits = liste_produits,
  liste_declinai_noms_produits = final_declinaisons
)})


# On regarde séparemment le data_ok et data_pas_ok
data_prod_tries <- resultats_2$data_ok
data_prod_pas_tries <- resultats_2$data_pas_ok

```

# VII) Fusion de tous les fichiers de cagette

```{r,warning=FALSE}

# On extrait les tables cagette dans une liste
liste_datasets_cagette <- liste_datasets_final[indices_cagette]
```

```{r,warning=FALSE}
################## On fusionne les tables pommes ensemble

# Étape 1 : renommer les éléments pour grouper
noms_groupes <- sub("part_\\d+_", "", names(liste_datasets_cagette))

# Étape 2 : fusionner les data.frames par groupe
liste_datasets_cagette <- lapply(
  split(liste_datasets_cagette, noms_groupes),
  function(groupe) do.call(rbind, groupe)
)


```

```{r}
#################### On ajoute la nouvelle colonne nom_produit à toutes les tables cagette
# Liste des produits
liste_produits_alimentaires <- c(
  "Abricot", "Asperge", "Aubergine","Banane","Carotte","Cerise","Chou fleur",
  "Clémentine", "Concombre","Courgette","Céleri branche","Endive","Fraise",
  "Haricot vert","Kiwi","Laitue","Melon","Nectarine","Oignon","Poire","Poireau","Poivron",
  "Pomme de terre","Pomme","Potiron","Prune","Pêche","Raisin","Tomate")

# Nettoyer les noms : minuscules + suppression des accents + remplacement des espaces par _
nettoyer_nom <- function(x) {
  x %>%
    tolower() %>%
    stri_trans_general("Latin-ASCII") %>%
    gsub("[^a-z0-9]+", " ", .) %>%
    gsub("_+$", "", .) %>%
    gsub("^_+", "", .)
}

# Noms nettoyés des produits
produits_nettoyes <- sapply(liste_produits_alimentaires, nettoyer_nom, USE.NAMES = FALSE)

# Création d'une table de correspondance entre produits nettoyés et noms originaux
produits_df <- data.frame(
  produit_clean = produits_nettoyes,
  produit_label = tolower(liste_produits_alimentaires),
  stringsAsFactors = FALSE
)

# Ajouter la colonne nom_produit dans chaque data frame
liste_datasets_cagette_nettoyee <- lapply(names(liste_datasets_cagette), function(nom_df) {
  df <- liste_datasets_cagette[[nom_df]]
  
  # Extraire le nom du produit dans le nom de la table
  produit_nom_match <- sub("cagette_(.*)_20[0-9]{2}", "\\1", nom_df)
  
  # Nettoyage de ce nom pour le faire correspondre
  produit_nom_clean <- nettoyer_nom(produit_nom_match)
  
  # Recherche du nom d'origine
  produit_label <- produits_df$produit_label[match(produit_nom_clean, produits_df$produit_clean)]
  
  # Ajoute directement le nom nettoyé (sans accents)
  df$nom_produit <- produits_df$produit_clean[match(produit_nom_clean, produits_df$produit_clean)]

  
  return(df)
})

# Réattribution des noms à la liste
names(liste_datasets_cagette_nettoyee) <- names(liste_datasets_cagette)

```

```{r}
# On fusionne toutes les tables de cagette en une seule
liste_finale_datasets_cagette <- do.call(rbind, liste_datasets_cagette_nettoyee)
View(liste_finale_datasets_cagette)
```

# VIII) Fusion de tous les fichiers issus de toutes les plateformes

```{r}
# On supprime la colonne name_clean de data_prod_tries
data_prod_tries <- data_prod_tries |> select(-c("name_clean"))

# On fusionne toutes les tables de cagette en une seule
datasets_tts_plateformes <- rbind(liste_finale_datasets_cagette,data_prod_tries)
View(datasets_tts_plateformes)

```

# IV) Tableau de comptage du nombre de levels par produit

```{r}

table_comptage_levels_par_prod <- datasets_tts_plateformes %>%
  group_by(nom_produit) %>%
  summarise(`Nombre de levels` = n_distinct(productName)) %>%
  arrange(desc(`Nombre de levels`)) %>%
  rename(`Nom de produit` = nom_produit)

View(table_comptage_levels_par_prod)
```

# X) Tableaux de comptages du nombre d'occurrences des autres produits pour un produit donné

```{r}
# On sélectionne les lignes non vides de data_prod_pas_tries
data_produits_multiples <- data_prod_pas_tries |> filter(!is.na(nom_produit))
```

```{r}

# Liste des 37 produits nettoyés
liste_37_prod_nettoyes <- sapply(liste_produits, nettoyer_nom, USE.NAMES = FALSE)

# Étape 1 : Créer un ID par ligne
data_clean <- data_produits_multiples %>%
  mutate(id_ligne = row_number())

# Étape 2 : Séparer les noms de produits par ligne
data_split <- data_clean %>%
  separate_rows(nom_produit, sep = ";") %>%
  mutate(nom_produit = str_trim(nom_produit)) %>%
  filter(nom_produit %in% liste_37_prod_nettoyes)

# Étape 3 : Liste des produits par ligne
data_grouped <- data_split %>%
  group_by(id_ligne) %>%
  summarise(produits = list(nom_produit), .groups = "drop")

# Étape 4 : Calcul des cooccurrences (cross-join par ligne)
cooccurrences <- data_grouped %>%
  mutate(paires = map(produits, ~ {
    expand.grid(p1 = .x, p2 = .x, stringsAsFactors = FALSE)
  })) %>%
  unnest(paires) %>%
  filter(p1 != p2)

# Étape 5 : Compter les cooccurrences
co_counts <- cooccurrences %>%
  count(p1, p2, name = "nb_occurrences")

# Étape 6 : Générer les 37 dataframes
liste_dataframes <- map(set_names(liste_37_prod_nettoyes), function(produit) {
  autres_produits <- setdiff(liste_37_prod_nettoyes, produit)
  tibble(`Nom de produit` = autres_produits) %>%
    left_join(
      co_counts %>% filter(p1 == produit) %>%
        select(`Nom de produit` = p2, `Nombre d'occurrences` = nb_occurrences),
      by = "Nom de produit"
    ) %>%
    mutate(`Nombre d'occurrences` = coalesce(`Nombre d'occurrences`, 0L))
})

```

```{r}
# Trier chaque dataframe par ordre décroissant d'occurrences
liste_dataframes_tries <- map(liste_dataframes, ~ {
  arrange(.x, desc(`Nombre d'occurrences`))
})

# On regarde les tableaux de comptages 
View(liste_dataframes_tries)

```
