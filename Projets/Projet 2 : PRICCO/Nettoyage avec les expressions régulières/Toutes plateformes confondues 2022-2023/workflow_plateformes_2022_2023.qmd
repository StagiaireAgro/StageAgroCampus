---
title: "workflow_plateformes_2022_2023"
format: html
editor: visual
---

# I) Chargement des bibliothèques nécessaires

```{r,message=FALSE}

# ---- Définir les packages nécessaires ----

required_packages  <- c(
  "vroom",       # lecture rapide de CSV/TSV
  "stringr",     # manipulation de chaînes
  "stringi",     # normalisation de chaînes (accents, etc.)
  "fs",          # gestion de fichiers
  "tidyverse",   # méta-package (ggplot2, dplyr, tidyr, etc.)
  "purrr",       # programmation fonctionnelle (déjà dans tidyverse)
  "writexl",     # sauvegarde de fichiers xlsx
  "tibble",      # tibbles modernes (déjà dans tidyverse)
  "ollamar",     # modèle de langage
  "pbapply",     # barre de progression pour apply
  "readxl",      # lecture de fichiers Excel
  "stringdist"   # distance de Levenshtein
)

# Fonction pour vérifier et installer les packages
install_and_load_packages <- function(packages) {
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      message(paste("Le package", pkg, "n'est pas installé. Tentative d'installation..."))
      install.packages(pkg, dependencies = TRUE)
      if (!require(pkg, character.only = TRUE)) {
        stop(paste("Impossible d'installer et de charger le package", pkg, ". Veuillez vérifier votre connexion internet ou les dépôts R."))
      }
    }
  }
}

install_and_load_packages(required_packages)

```

# II) Documentation des variables d'intérêts pour le calcul du prix au kilogramme

| Variable | Définition | Unité |
|------------------------|------------------------|------------------------|
| orderProductPrice | Unités de mesure | Euro |
| orderQuantity | Nombre d'une unité de produit acheté | Sans unité |
| mois | Mois | Mois |
| annee | Année | Année |
| productName | Noms du produit | Sans unité |
| productIsOrganic | Produit est bio | Sans unité |
| productConditioningQuantity | Poids d'une unité de produit | Gramme, kilogramme, pièce |
| productConditioningUnit | Unités de mesure | gramme, kilogramme, pièce |
| distributionZipCode | Code postal | Sans unité |
| plateforme | Plateformes partenaires du projet Pricco | Sans unité |

# III) Importation des fichiers

Ce code lit automatiquement tous les fichiers .csv présents dans un dossier (et ses sous-dossiers), les charge dans une liste, puis nomme chaque élément de cette liste selon le nom de fichier correspondant. C'est une méthode efficace pour manipuler plusieurs jeux de données en une seule opération.

```{r,message=FALSE}
# Définition du dossier racine contenant les fichiers CSV à importer
dossier_racine <- "data/2022-2023"

# Recherche récursive de tous les fichiers CSV dans le dossier spécifié
# `recurse = TRUE` permet de chercher dans les sous-dossiers
# `glob = "*.csv"` filtre uniquement les fichiers ayant l'extension .csv
fichiers <- dir_ls(path = dossier_racine, recurse = TRUE, glob = "*.csv")

# Extraction du nom de chaque fichier (sans chemin ni extension)
# - path_file() extrait le nom du fichier à partir du chemin complet
# - path_ext_remove() retire l'extension (.csv)
noms_fichiers <- path_ext_remove(path_file(fichiers))

# Lecture de chaque fichier CSV avec vroom()
# lapply applique la fonction vroom() à chaque élément de la liste 'fichiers'
datasets <- lapply(fichiers, function(file) vroom(file))

# Attribution des noms de fichiers (sans extension) comme noms des éléments de la liste 'datasets'
names(datasets) <- noms_fichiers

# Affichage de la liste de datasets dans le visualiseur RStudio
View(datasets)

```

# IV) Harmonisation des noms de colonnes de toutes les plateformes

Cette étape permet de préparer les deux jeux de données (ruche_oui_2022 et ruche_oui_2023) en ajoutant une nouvelle colonne appelée productIsOrganic, qui sera ensuite renseignée avec des valeurs manquantes.

```{r}
# On ajoute une colonne vide (remplie de NA) nommée 'productIsOrganic'
# dans le dataset 'ruche_oui_2022' pour indiquer si un produit est bio
datasets$ruche_oui_2022$productIsOrganic <- NA

# Même opération pour le dataset 'ruche_oui_2023'
datasets$ruche_oui_2023$productIsOrganic <- NA

```

Ce script permet d’harmoniser les structures de données issues de différentes plateformes (Cagette, Ruche, Socleo, CoopCircuit) pour faciliter leur fusion et leur analyse en aval. On standardise les colonnes et ajoute une information sur la provenance (plateforme).

```{r}
# Définition des colonnes à conserver pour les datasets provenant de Cagette
colonne_cagette_a_garder <- c(
  "orderProductPrice", "orderQuantity", "mois", "annee", "productName", 
  "productIsOrganic", "productConditioningQuantity", "productConditioningUnit", 
  "distributionZipCode"
)

# Identification des datasets dont le nom commence par "cagette"
indices_cagette <- startsWith(names(datasets), "cagette")

# Sélection des colonnes souhaitées pour chaque dataset de Cagette
datasets[indices_cagette] <- lapply(datasets[indices_cagette], function(x) {
  select(x, any_of(colonne_cagette_a_garder))
})

# Définition des colonnes à conserver pour les datasets de La Ruche Qui Dit Oui
colonne_ruche_a_garder <- c(
  "price_ttc_item", "nb_item", "mois", "annee", "product_name", "productIsOrganic",
  "weight_raw_item", "quantityunit", "hive_zipcode"
)

# Identification des datasets dont le nom commence par "ruche"
indices_ruche <- startsWith(names(datasets), "ruche")

# Sélection des colonnes souhaitées pour chaque dataset de La Ruche
datasets[indices_ruche] <- lapply(datasets[indices_ruche], function(x) {
  select(x, any_of(colonne_ruche_a_garder))
})

# Définition des colonnes à conserver pour les datasets de Socleo
colonne_socleo_a_garder <- c(
  "value", "quantite_com", "mois", "annee", "name", "is_organic",
  "quantite_cond", "unite_conditionnement", "code_postal"
)

# Identification des datasets dont le nom commence par "socleo"
indices_socleo <- startsWith(names(datasets), "socleo")

# Sélection des colonnes souhaitées pour chaque dataset de Socleo
datasets[indices_socleo] <- lapply(datasets[indices_socleo], function(x) {
  select(x, any_of(colonne_socleo_a_garder))
})

# Définition des colonnes à conserver pour les datasets de CoopCircuit
colonne_coop_circuit_a_garder <- c(
  "price", "quantite_unite", "mois", "annee", "name", "is_organic", 
  "quantite_cond", "conditionnement", "code_postal"
)

# Identification des datasets dont le nom commence par "coop_circuit"
indices_coop_circuit <- startsWith(names(datasets), "coop_circuit")

# Sélection des colonnes souhaitées pour chaque dataset de CoopCircuit
datasets[indices_coop_circuit] <- lapply(datasets[indices_coop_circuit], function(x) {
  select(x, any_of(colonne_coop_circuit_a_garder))
})

# Harmonisation des noms de colonnes pour toutes les plateformes autres que Cagette
# On renomme leurs colonnes pour correspondre à celles de Cagette
datasets[!indices_cagette] <- lapply(datasets[!indices_cagette], function(df) {
  df <- select(df, everything())  # Réorganise les colonnes si nécessaire
  colnames(df) <- colonne_cagette_a_garder  # Applique les noms standardisés
  return(df)
})

# Création d'une nouvelle liste contenant les datasets enrichis d'une colonne "plateforme"
# Cette colonne est extraite du nom de chaque dataset (ex: "ruche_oui_2022" --> "ruche")
liste_datasets_final <- lapply(names(datasets), function(nom) {
  df <- datasets[[nom]]
  df$plateforme <- str_split(nom, "_")[[1]][1]  # Extraction de la plateforme à partir du nom
  df
})

# Attribution des noms d’origine aux éléments de la liste finale
names(liste_datasets_final) <- names(datasets)

```

# V) Transformations des données de socleo

## a) La fonction

```{r}
nettoyer_et_agreger <- function(df) {
  # Suppression des lignes avec orderQuantity ou orderProductPrice <= 0
  df <- df %>%
    filter(orderQuantity > 0,
           orderProductPrice > 0)
  
  df <- df %>%
    mutate(orderProductPrice = orderProductPrice / orderQuantity)
  
  # Agrégation
  df_aggrege <- df %>%
    group_by(across(c(-orderQuantity))) %>% # Exclure orderQuantity des clés de groupement
    summarise(
      orderQuantity = sum(orderQuantity),
      .groups = 'drop'
    )
  
  return(df_aggrege)
}

```

## b) Application de la fonction 

```{r}

liste_datasets_final[indices_socleo] <- lapply(
  liste_datasets_final[indices_socleo],
  function(d) {
    if (!inherits(d, "data.frame")) {
      d <- as.data.frame(d)
    }
    nettoyer_et_agreger(d)
  }
)

```


# VI) Fusion de tous les jeux de données sauf cagette

Ce code sert à regrouper dans un seul tableau tous les jeux de données hors Cagette. En effet, les données de cagette étant déjà séparées en 37 tables de produit.

```{r,warning=FALSE}
# Création d'une nouvelle liste ne contenant que les datasets 
# qui ne proviennent PAS de Cagette (on les exclut grâce à !indices_cagette)
liste_datasets_final_sans_cagette <- liste_datasets_final[!indices_cagette]

# Fusion de tous les datasets restants (Ruche, Socleo, CoopCircuit) en un seul data frame
# do.call avec rbind permet d'empiler toutes les lignes des datasets ensemble
combinaison <- do.call(rbind, liste_datasets_final_sans_cagette)

```

# VII) Associer le bon nom de produit

## a) Définition de la liste de produits

```{r}
# Liste des produits alimentaires à rechercher
liste_produits <- c(
  "Clémentine", "Tomate", "Carotte", "Cerise", "Chou fleur",
  "Fraise", "Kiwi", "Lait", "Oeuf", "Poireau", "Poire", "Raisin",
  "Haricot vert", "Noix", "Pomme", "Boeuf", "Porc", "Poulet",
  "Laitue", "Lentille", "Abricot", "Pomme de terre", "Oignon",
  "Courgette", "Aubergine", "Asperge", "Banane", "Poivron",
  "Jus de pomme", "Celeri branche", "Concombre", "Prune",
  "Peche", "Potiron", "Melon", "Endive", "Nectarine")

# Mise en minuscules pour correspondance plus facile
liste_produits <- str_to_lower(liste_produits)

# On supprime les tirets pour correspondance plus facile
liste_produits <- gsub("-", " ", liste_produits, ignore.case = TRUE)

# On supprime les accents pour correspondance plus facile
liste_produits <- stri_trans_general(liste_produits, "Latin-ASCII")

# On ordonne la liste des noms de produits de manière decroissante selon
# le nombre de caractere de chaque mots
ordre <- order(nchar(gsub(" ", "", liste_produits)), decreasing = TRUE)
liste_produits <- liste_produits[ordre]
```

## b) Liste contenant toutes les déclinaisons possibles pour chaque nom de produit

```{r}
# Nettoyer une chaine de caractères (-> ici liste de noms de produits)
nettoyer <- function(x) {
  # Convertit les caractères en minuscules et enlève les accents (ex: "É" devient "e")
  x <- stri_trans_general(str_to_lower(x), "Latin-ASCII")
  # Supprime tous les caractères non alphabétiques (hors a-z et espace)
  x <- str_replace_all(x, "[^a-z ]", "")
  # Supprime les espaces au début et à la fin de chaque chaîne
  x <- trimws(x)
  # Retourne le vecteur nettoyé
  return(x)
}

# Générer des expressions régulières à partir d'un mots ou liste de mots
creer_regex <- function(mots, suffixe = "(e?s)?", collapse = ".*") {
  # Applique la construction de regex à chaque mot ou expression
  sapply(mots, function(terme) {
    # Découpe l'expression en mots individuels
    tokens <- str_split(terme, " ")[[1]]
    # Ajoute le suffixe (par défaut : formes féminines/plurielles) à chaque mot
    regex_tokens <- paste0(tokens, suffixe)
    # Combine les morceaux avec '.*' entre eux pour matcher des variations textuelles
    paste0(regex_tokens, collapse = collapse)
  })
}

# Crée un fichier Excel standard pour permettre l'ajout d'autres déclinaisons
creer_fichier_excel <- function(liste_de_produits, fichier = "autres_declinaisons.xlsx") {
  classeur <- createWorkbook() # Crée un nouveau classeur Excel
  addWorksheet(classeur, "Ajoutez autres déclinaisons") # Ajoute une feuille nommée
  
  # Crée un tableau avec une colonne "Nom de produit" et une colonne vide "Autres déclinaisons"
  data <- data.frame(
    "Nom de produit" = liste_de_produits,
    "Autres déclinaisons" = "",
    check.names = FALSE
  )
  
  # Écrit le tableau dans la feuille Excel à partir de la première ligne avec les noms de colonnes
  writeData(
    classeur, 
    sheet = "Ajoutez autres déclinaisons", 
    x = data, 
    startRow = 1,
    colNames = TRUE
  )
  
  # Calcule le nombre total de lignes (données + en-tête) et de colonnes
  n_rows <- nrow(data) + 1
  n_cols <- ncol(data)
  
  # Calcule des largeurs de colonnes pour lisibilité (+5 caractères de marge)
  largeurs <- nchar(colnames(data)) + 5
  setColWidths(classeur, sheet = "Ajoutez autres déclinaisons", cols = 1:n_cols, widths = largeurs)
  
  # Crée un style pour l'en-tête (texte en gras et taille de police 12)
  header_style <- createStyle(textDecoration = "bold", fontSize = 12)
  addStyle(
    wb = classeur,
    sheet = "Ajoutez autres déclinaisons",
    style = header_style,
    rows = 1,
    cols = 1:n_cols,
    gridExpand = TRUE,
    stack = TRUE
  )
  
  # Crée un style déverrouillé pour permettre la modification des cellules (hors en-tête)
  unlocked_style <- createStyle(locked = FALSE)
  addStyle(
    wb = classeur,
    sheet = "Ajoutez autres déclinaisons",
    style = unlocked_style,
    rows = 2:n_rows,
    cols = 1:n_cols,
    gridExpand = TRUE,
    stack = TRUE
  )
  
  # Protège la feuille tout en autorisant la sélection des cellules verrouillées et déverrouillées
  protectWorksheet(
    wb = classeur,
    sheet = "Ajoutez autres déclinaisons",
    protect = TRUE,
    lockSelectingLockedCells = FALSE,
    lockSelectingUnlockedCells = FALSE
  )
  
  # Enregistre le fichier Excel sous le nom spécifié (en écrasant s’il existe)
  saveWorkbook(classeur, fichier, overwrite = TRUE)
}

# Fonction pour extraire toutes les déclinaisons des noms de produits à partir d'un dataset et d’un fichier externe facultatif
trouver_declinaisons_nom_produit <- 
  function(dataset, col_produit, ls_produit, regex, fichier = NULL) {
  # Nettoie les noms de produits dans la colonne spécifiée du dataset
  noms_des_produits <- nettoyer(dataset[[col_produit]])
  # Supprime les doublons parmi les noms nettoyés
  noms_des_produits_uniques <- unique(noms_des_produits)
  # Pour chaque expression régulière, extrait les correspondances dans les noms de produits uniques
  liste_declinaisons <- sapply(seq_along(regex), function(i) {
    extractions <- str_extract(noms_des_produits_uniques, regex[i]) # Applique la regex
    extractions <- extractions[!is.na(extractions) & extractions != ""] # Filtre les vides ou NA
    unique(extractions) # Supprime les doublons dans les extractions
  }, simplify = FALSE)
  
  # Donne à chaque élément de la liste le nom du produit correspondant
  names(liste_declinaisons) <- ls_produit
  
  # Si un fichier externe est fourni, ajouter les déclinaisons supplémentaires
  if(!is.null(fichier)==TRUE){
    fichier <- na.omit(fichier) # Supprime les lignes contenant des NA
    fichier[["Nom de produit"]] <- nettoyer(fichier[["Nom de produit"]]) # Nettoie les noms de produits du fichier
    sapply(fichier[["Nom de produit"]], function(prod){
      res <- pull(fichier[fichier[["Nom de produit"]]==prod,"Autres déclinaisons"]) # Récupère les déclinaisons associées au produit
      declinaisons_suppl <- unlist(str_split(res, ";")) # Sépare les déclinaisons par ";"
      liste_declinaisons[[prod]] <<- unique(c(liste_declinaisons[[prod]], declinaisons_suppl)) # Ajoute les déclinaisons à la liste existante en supprimant les doublons
    })
  }
  # Retourne la liste complète des déclinaisons
  return(liste_declinaisons)
}
```

```{r}
# Creer les expressions reguliere de la liste des noms de produits
regex <- creer_regex(liste_produits) 
# Declinaison obtenues de manière automatique
final_declinaisons <- trouver_declinaisons_nom_produit(
    dataset = combinaison,
    col_produit = "productName",
    ls_produit = liste_produits,
    regex = regex
  )

```

## c) Correspondance automatique et nettoyage intelligent des noms de produits avec gestion des cas ambigus

Cette fonction vise à faire correspondre automatiquement des noms de produits à une liste de produits standard, en gérant les variations d'écriture, les accents, les tirets, etc. Elle isole aussi les cas ambigus pour traitement manuel ou ultérieur, tout en essayant de les nettoyer intelligemment.

```{r}
# Fonction de séparation des fichiers par nom de produit
# Prend en entrée : 
# - data : un data frame contenant une colonne productName
# - liste_produits : noms standards des produits
# - liste_declinai_noms_produits : déclinaisons possibles de chaque nom de produit
associer_noms_produits <- function(data, liste_produits, liste_declinai_noms_produits) {

  #### Étape 0 : Nettoyage du nom de produit
  data <- data %>%
    mutate(
      name_clean = productName %>%
        str_to_lower() %>%  # Mise en minuscules
        stri_trans_general("Latin-ASCII") %>%  # Suppression des accents
        gsub("-", " ", ., ignore.case = TRUE)  # Remplacement des tirets par des espaces
    )

  #### Étape 1 : Extraction des valeurs uniques dans `name_clean`
  levels_produits <- levels(as.factor(data$name_clean))

  #### Étape 2 : Création d’une matrice de correspondance entre noms et déclinaisons
  matrice_presence <- sapply(liste_declinai_noms_produits, function(declinaisons) {
    sapply(levels_produits, function(level) {
      any(str_detect(level, fixed(declinaisons))) * 1  # 1 si correspondance, 0 sinon
    })
  })

  # Transposition de la matrice pour avoir les produits en colonnes
  matrice_presence <- t(matrice_presence)

  # Calcul du nombre de correspondances pour chaque nom observé
  nb_variantes_noms <- colSums(matrice_presence)

  # Ajout d'une ligne résumant le nombre de correspondances par niveau
  matrice_presence <- rbind(matrice_presence, nb_variantes_noms)

  #### Étape 3 : Identification des noms qui correspondent à un seul produit
  levels_uniques <- names(nb_variantes_noms[nb_variantes_noms == 1])

  # On garde uniquement les colonnes de la matrice avec correspondance unique
  matrice_uniques <- matrice_presence[-nrow(matrice_presence), levels_uniques, drop = FALSE]

  #### Étape 4 : Création d’un vecteur de noms de produit bien identifiés
  vecteur_nom_produit <- sapply(levels_uniques, function(level) {
    idx <- which(matrice_uniques[, level] == 1)
    if (length(idx) == 1) {
      return(liste_produits[idx])
    } else {
      return(NA)
    }
  }, USE.NAMES = TRUE)

  # Suppression des cas NA (non identifiables de manière unique)
  vecteur_nom_produit <- vecteur_nom_produit[!is.na(vecteur_nom_produit)]

  # Création du data frame de correspondance nom nettoyé ↔ nom standard
  df_correspondance <- data.frame(
    name_clean = names(vecteur_nom_produit),
    nom_produit = unname(vecteur_nom_produit),
    stringsAsFactors = FALSE
  )

  #### Étape 5 : Création d’un sous-ensemble des données bien identifiées
  data_ok <- data %>%
    filter(name_clean %in% df_correspondance$name_clean) %>%
    left_join(df_correspondance, by = "name_clean")

  #### Étape 6 : Identification des noms ambigus ou non identifiés
  levels_pas_ok <- names(nb_variantes_noms[nb_variantes_noms != 1])

  # Création de la matrice pour les cas ambigus
  matrice_pas_ok <- matrice_presence[-nrow(matrice_presence), levels_pas_ok, drop = FALSE]

  # Création d’un vecteur listant tous les noms candidats pour chaque nom ambigus
  vecteur_nom_pas_ok <- sapply(levels_pas_ok, function(level) {
    idx <- which(matrice_pas_ok[, level] == 1)
    if (length(idx) == 0) {
      return(NA)
    } else {
      return(paste(liste_produits[idx], collapse = ";"))  # concatène les noms possibles
    }
  }, USE.NAMES = TRUE)

  # Data frame pour ces correspondances ambiguës
  df_correspondance_pas_ok <- data.frame(
    name_clean = names(vecteur_nom_pas_ok),
    nom_produit = unname(vecteur_nom_pas_ok),
    stringsAsFactors = FALSE
  )

  #### Étape 7 : Création du sous-ensemble avec noms ambigus ou multiples
  data_pas_ok <- data %>%
    filter(name_clean %in% df_correspondance_pas_ok$name_clean) %>%
    left_join(df_correspondance_pas_ok, by = "name_clean")

  #### Étape 8 : Extraction des lignes avec plusieurs correspondances (séparées par ;) 
  data_ambigus <- data_pas_ok %>%
    filter(str_detect(nom_produit, ";"))

  #### Étape 9 : Nettoyage des noms emboîtés pour éliminer les doublons inclus
  data_ambigus_clean <- data_ambigus %>%
    rowwise() %>%
    mutate(
      noms_list = list(str_split(nom_produit, ";")[[1]] %>% str_trim())  # on découpe et nettoie
    ) %>%
    mutate(
      noms_clean = list({
        noms <- noms_list
        # Supprime les noms qui sont contenus dans un autre
        noms[!sapply(noms, function(x) any(noms != x & str_detect(noms, fixed(x))))]
      })
    ) %>%
    mutate(
      nom_produit_new = ifelse(length(noms_clean) == 1, noms_clean[[1]], paste(noms_clean, collapse = ";"))
    ) %>%
    ungroup()

  #### Étape 10 : Extraire les lignes désormais associées à un seul nom
  data_deplaces <- data_ambigus_clean %>%
    filter(!str_detect(nom_produit_new, ";")) %>%  # gardes uniquement les cas désormais uniques
    select(-nom_produit, -noms_list, -noms_clean) %>%
    rename(nom_produit = nom_produit_new)

  #### Étape 11 : Mise à jour du dataset des correspondances uniques avec les lignes nettoyées
  data_ok <- bind_rows(data_ok, data_deplaces)

  #### Étape 12 : Suppression des lignes déplacées dans les données ambigües
  data_pas_ok <- data_pas_ok %>%
    filter(!(name_clean %in% data_deplaces$name_clean))

  # Retourne une liste avec les données bien identifiées et les autres
  return(list(data_ok = data_ok, data_pas_ok = data_pas_ok))
}

```

## d) Application de la fonction correspondance automatique

Ce code permet d’exécuter la fonction d’association des produits, puis de séparer les résultats en deux groupes : ceux qui ont pu être associés de façon claire (data_ok) et ceux qui nécessitent un traitement ou une vérification supplémentaire (data_pas_ok).

```{r,message=FALSE,warning=FALSE}
# Application de la fonction d'identification des produits à partir des noms
# system.time() permet de mesurer le temps d'exécution du bloc de code
system.time({ 
  resultats_2 <- associer_noms_produits(
    data = combinaison,  # Le jeu de données fusionné (sans Cagette)
    liste_produits = liste_produits,  # Liste des noms de produits standardisés
    liste_declinai_noms_produits = final_declinaisons  # Liste des déclinaisons textuelles pour chaque produit
  )
})

# Récupération des lignes avec correspondance unique : noms de produit bien identifiés
data_prod_tries <- resultats_2$data_ok

# Récupération des lignes avec correspondances absentes ou ambiguës (plusieurs correspondances possibles)
data_prod_pas_tries <- resultats_2$data_pas_ok


```
```{r}
library(parallel)
num_cores <- detectCores() - 1 # Utiliser tous les cœurs moins un
cl <- makeCluster(num_cores)

resultats_2 <- associer_noms_produits(
    data = combinaison,  # Le jeu de données fusionné (sans Cagette)
    liste_produits = liste_produits,  # Liste des noms de produits standardisés
    liste_declinai_noms_produits = final_declinaisons  # Liste des déclinaisons textuelles pour chaque produit
  )

stopCluster(cl)
```


# VIII) Fusion de tous les fichiers de cagette

Ce code permet de créer une sous-liste contenant uniquement les datasets de Cagette, pour les traiter à part des autres plateformes si nécessaire.

```{r,warning=FALSE}

# Extraction des jeux de données provenant uniquement de la plateforme Cagette
# On utilise les indices repérés précédemment (indices_cagette) pour filtrer la liste
liste_datasets_cagette <- liste_datasets_final[indices_cagette]

```

Ce bloc permet de reconstituer les tables de produits scindées en plusieurs fichiers (part_x\_...), en les fusionnant proprement et en supprimant les doublons éventuels. C'est une étape cruciale si les exports de données étaient fragmentés.

```{r,warning=FALSE}
################## On fusionne les tables Pomme ensemble ##################

# Étape 1 : Renommer les éléments de la liste pour regrouper les fichiers issus d'une même table
# On supprime la partie "part_x_" dans les noms (ex : "part_1_cagette_Pomme_2022" → "cagette_Pomme_2022")
noms_groupes <- sub("part_\\d+_", "", names(liste_datasets_cagette))

# Étape 2 : Fusionner les data.frames par groupe de noms identiques (après nettoyage)
# - split() crée une liste de sous-groupes en fonction des nouveaux noms
# - do.call(rbind, ...) empile les lignes de tous les fichiers d’un même groupe
liste_datasets_cagette <- lapply(
  split(liste_datasets_cagette, noms_groupes),
  function(groupe) do.call(rbind, groupe)
)

# Étape 3 : Supprimer les doublons dans les jeux de données fusionnés pour la Pomme
# On conserve uniquement les lignes uniques pour éviter les redondances
liste_datasets_cagette[["cagette_Pomme_2022"]] <- unique(liste_datasets_cagette[["cagette_Pomme_2022"]])
liste_datasets_cagette[["cagette_Pomme_2023"]] <- unique(liste_datasets_cagette[["cagette_Pomme_2023"]])


```

```{r}
# On fusionne toutes les tables de cagette en une seule
liste_finale_datasets_cagette <- do.call(rbind, liste_datasets_cagette)
```

# IX) On vérifie la pertinence des données déjà classées pour cagette

Ce code utilise la fonction trouver_declinaisons_nom_produit() pour analyser les noms de produits et détecter les différentes variantes textuelles utilisées dans les données issues de Cagette. Cela permet ensuite de faciliter la normalisation ou le regroupement des produits.

```{r}

# On identifie toutes les déclinaisons possibles des noms de produits dans les fichiers Cagette
# Cette étape permet de repérer les différentes façons dont un même produit peut être nommé (ex: "pomme", "Pommes", "pom'")

vect_decli_cagette <- trouver_declinaisons_nom_produit(
  dataset = liste_finale_datasets_cagette,  # Liste des jeux de données Cagette nettoyés
  col_produit = "productName",              # Nom de la colonne contenant les noms de produits à analyser
  ls_produit = liste_produits,              # Liste de référence des noms de produits standards
  regex = regex                             # Expression(s) régulière(s) utilisée(s) pour repérer les variantes
)

```

```{r}
# Attribution du bon nom de produit (standardisé parmi la liste de 37) à chaque ligne des données Cagette

# Application de la fonction d'association des noms de produits à la liste des produits standards
# system.time() permet de mesurer la durée d'exécution de la fonction
system.time({ 
  liste_cagette_trie_et_pas_trie <- associer_noms_produits(
    data = liste_finale_datasets_cagette,             # Données Cagette consolidées
    liste_produits = liste_produits,                  # Liste des noms de produits standardisés (ex : "Pomme", "Tomate"...)
    liste_declinai_noms_produits = vect_decli_cagette # Variantes textuelles identifiées dans les noms de produits
  )
})

# Séparation des résultats : lignes bien identifiées vs lignes ambiguës ou non reconnues

# Données bien identifiées : chaque ligne est associée de façon unique à un produit de la liste
cagette_prod_tries <- liste_cagette_trie_et_pas_trie$data_ok

# Données problématiques : aucune correspondance ou correspondances multiples (à traiter manuellement ou affiner)
cagette_prod_pas_tries <- liste_cagette_trie_et_pas_trie$data_pas_ok


```

# X) Fusion de tous les fichiers de produits triés issus de toutes les plateformes

Ce bloc permet de nettoyer les données en supprimant les colonnes intermédiaires et de construire un jeu de données consolidé contenant toutes les lignes correctement associées à un nom de produit standard, quelle que soit la plateforme d’origine.

```{r}
# Suppression de la colonne temporaire 'name_clean' dans le jeu de données produit final (hors Cagette)
# Cette colonne servait au nettoyage/comparaison des noms de produits, mais n'est plus nécessaire
data_prod_tries <- data_prod_tries |> select(-c("name_clean"))

# Suppression de la colonne 'name_clean' dans les données Cagette également
cagette_prod_tries <- cagette_prod_tries |> select(-c("name_clean"))

# Fusion des jeux de données Cagette et hors Cagette contenant uniquement les produits bien identifiés
# rbind permet d’empiler toutes les lignes dans une table finale unique
datasets_tts_plateformes_prod_tries <- rbind(cagette_prod_tries, data_prod_tries)


```


# XI) Fusion des fichiers de produits pas triés en un seul

Ce code permet de rassembler tous les cas problématiques en une seule table, ce qui est utile pour une vérification manuelle, un traitement ultérieur ou pour suivre la qualité du matching produit.

```{r}

# Fusion des jeux de données Cagette et hors Cagette contenant les lignes
# dont les noms de produits n'ont pas pu être identifiés de manière unique

# Cela inclut les noms ambigus (plusieurs correspondances possibles) ou non reconnus

data_prod_pas_tries_tts_platatefor <- rbind(cagette_prod_pas_tries, data_prod_pas_tries)


```


# XII) Récupérer des noms de produits 

## a) La fonction 

Cette fonction permet de récupéer des donnnées pour des produits de data_prod_pas_tries_tts_platatefor qu'on souhaite garder.

Elle prend en paramètre le jeu de données, le nom de la colonne où rechercher les produits qu'on souhaite garder et un vecteur des noms de produit à récupérer (produits_cibles). Elle retourne un jeu de données des produits contenant dans leur noms tous les mots des noms de produits du vecteur produits_cibles.   

```{r}
recuperer_produits <- function(df, colonne="productName", produits_cibles, cible=TRUE) {
  require(stringdist)
  require(stringr)
  
  # Fonction de nettoyage des noms
  clean_name <- function(x) {
    x <- tolower(x)
    x <- iconv(x, from = "UTF-8", to = "ASCII//TRANSLIT")
    x <- gsub("[^a-z0-9 ]", " ", x)
    x <- gsub("\\s+", " ", x)
    trimws(x) 
  }
  
  # Fonctionpour remplacer les caractères spéciaux regex
  remplacer_caract_speci_regex <- function(x) {
    stringr::str_replace_all(x, "([\\^$.|?*+()\\[\\]{}])", "\\\\\\1")
  }
  
  noms_prod_df <- df[[colonne]]             # Récupérer la colonne
  noms_prod_df_uniques <- levels(factor(noms_prod_df))   # Récupérer les levels
  
  # Nettoyage des noms
  noms_df_clean <- tolower(sapply(noms_prod_df_uniques, clean_name))
  produits_cibles_clean <- tolower(sapply(produits_cibles, clean_name))
  
  # Matching par combinaison de mots
  matched_levels  <- sapply(seq_along(noms_df_clean), function(i) {
    produit <- noms_df_clean[i]
    any(sapply(produits_cibles_clean, function(ref) {
      mots <- strsplit(ref, "\\s+")[[1]]
      mots <- remplacer_caract_speci_regex(mots)
      pattern <- paste0(".*", paste(mots, collapse = ".*"), ".*")
      grepl(pattern, produit)
    }))
  })
  
  # Les levels a retourner
  if (cible) {
  noms_retour <- noms_prod_df_uniques[matched_levels]
  } else{
  noms_retour <- noms_prod_df_uniques[!matched_levels]
  }
  
  # Filtrer le data frame
  res <- df[noms_prod_df %in% noms_retour, , drop = FALSE]
  
  return(res)
}

```

## b) Vecteur des noms de produits 

```{r}
# Liste de noms de référence
produits_cibles <- c("tomate cerise", "tomate boeuf", "laitue pomme", "tomate oeuf", "poivron tomate") 

#c("aubergine oeuf", "aubergine melongera", "carotte coeur boeuf", "cerise coeur boeuf", "chou fleur clémentine", "tomate clémentine", "boeuf joignon", "poire boeuf", "poivron corne boeuf", "tomate prune", "tomate raisin", "tomate poire", "tomate pomme")
```

## c) Application de la fonction 

```{r}

resultats <- recuperer_produits(data_prod_pas_tries_tts_platatefor, colonne = "productName", produits_cibles = produits_cibles)

```

## d) Vérification et ajout au données datasets_tts_plateformes_prod_tries

```{r}
resultats$name_clean <- NULL
datasets_tts_plateformes_prod_tries <- rbind(datasets_tts_plateformes_prod_tries, resultats)

```

# XIII) Ajout de la variable roduit déclassé

## a) La fonction

```{r}
ajouter_colonne_solde <- function(df, col_nom="productName") {
  require(stringr)
  
  # Fonction de nettoyage des noms
  clean_name <- function(x) {
    x <- tolower(x)
    x <- iconv(x, from = "UTF-8", to = "ASCII//TRANSLIT")
    x <- gsub("[^a-z0-9% ]", " ", x)
    x <- gsub("\\s+", " ", x)
    trimws(x) 
  }
  
  # Mots-clés indiquant un solde
  mots_soldes <- c("solde", "promo", "%", "declasse")
  pattern <- paste(mots_soldes, collapse = "|") # Construction du pattern
  
  noms_prod <- df[[col_nom]]
  noms_prod <- factor(noms_prod)
  levels_prod <- levels(noms_prod) # récupérer les levels
  levels_prod_clean <- sapply(levels_prod, clean_name)
  
  solde_levels <- as.integer(str_detect(tolower(levels_prod_clean), pattern))
  
  # Ajoute la colonne via les indices des niveaux
  df$solde <- solde_levels[as.integer(factor(noms_prod))]
  
  return(df)
}

```

## b) Application 

```{r}
datasets_tts_plateformes_prod_tries <- ajouter_colonne_solde(datasets_tts_plateformes_prod_tries)

```

# XIV) Standardiser l'écriture des unités

## a) Développement la fonction pour harmoniser l'écriture de unités

Cette fonction permet d'harmoniser l'écriture des unités de la colonne "productConditioningUnit", on remplace les variantes : kilogramme, Kg, kilo par kg ; gram, gr, grm, gramme par g ; L. , Litre par L ; PiÃ¨ce, Pièce, Pièce, pce par Piece. Les données initiales sont conservées dans la colonne "old_ productConditioningUnit".

```{r}
standardiser_unites <- function(data, col_source="productConditioningUnit") {
  
  # Nom de la colonne source pour la version standardisée
  col_std <- col_source
  
  # Nouveau nom pour garder l'ancienne version
  old_col <- paste0("old_", col_source)

  # Renomme l’ancienne colonne
  names(data)[names(data) == col_source] <- old_col
  
  
  # Création et copie la colonne source dans la colonne cible
  data[[col_std]] <- data[[old_col]]
  
  # Remplace les variantes de "kg" par "kg"
  data[[col_std]] <- gsub("\\b(Kg.|Kilogram)\\b", "kg", data[[col_std]], ignore.case = TRUE)
  
  # Remplace les variantes de "g" par "g"
  data[[col_std]] <- gsub("\\b(g.|Gram)\\b", "g", data[[col_std]], ignore.case = TRUE)
  
  # Remplace les variantes de "L" par "L"
  data[[col_std]] <- gsub("\\b(L.|Litre|ml.)\\b", "L", data[[col_std]], ignore.case = TRUE)
  
  # Remplace les variantes de "ml" par "ml"
  data[[col_std]] <- gsub("\\b(ml.)\\b", "ml", data[[col_std]], ignore.case = TRUE)
  
  # Remplace les variantes de "Piece" par "Piece"
  data[[col_std]] <- gsub("\\b(PiÃ¨ce|Pièce|Pièce|pce)\\b", "Piece", data[[col_std]], ignore.case = TRUE)
  
  return(data) 
}
```


## b) Vérifiver les levels des unités

Cette partie permet de vérifier que tous les levels des unités de la colonne productConditioningUnit on bien été ajouté à la fonction standardiser_unites(). Pour ajouter de nouveau levels dans gsub("\\b(gram|gramme|gr....) faire |new_levels.

```{r}
levels(factor(datasets_tts_plateformes_prod_tries$productConditioningUnit))
```

## c) Application de la fonction 

```{r}
datasets_tts_plateformes_prod_tries <- standardiser_unites(datasets_tts_plateformes_prod_tries, "productConditioningUnit")

```

## d) Vérifier les levels de la nouvelle colonne des Unités harmonisé

```{r}
cat("Unités de la colonne productConditioningUnit: ", "\n")
levels(factor(datasets_tts_plateformes_prod_tries$productConditioningUnit))
cat("\n")
cat("Unités de la colonne old_productConditioningUnit: ", "\n")
levels(factor(datasets_tts_plateformes_prod_tries$old_productConditioningUnit))
```


# XV) Garder les noms contenant des poids : Retirer les lignes pour lesquelles on ne peut pas calculer le prix au k

```{r}
# Récupérer les produits où l'unité correspond à Piece
datasets_tts_plateformes_prod_tries_unite_Pieces <- datasets_tts_plateformes_prod_tries[str_detect(datasets_tts_plateformes_prod_tries$productConditioningUnit, "Piece"), ]

# Conserver les produits où l'unité est différente de Piece (kg, g, L, ...)
datasets_tts_plateformes_prod_tries <- setdiff(datasets_tts_plateformes_prod_tries, datasets_tts_plateformes_prod_tries_unite_Pieces)

# Conserver parmi les proquits où l'unité correspond à Piece, ceux qui ont des chiffres dans leur nom
datasets_tts_plateformes_prod_tries_unite_Pieces <-  datasets_tts_plateformes_prod_tries_unite_Pieces[str_detect(datasets_tts_plateformes_prod_tries_unite_Pieces$productName, "[0-9]"), ]

# Fusionner les données (produits pour lesquelles ont peu calculer le prix)
datasets_tts_plateformes_prod_tries <- union(datasets_tts_plateformes_prod_tries, datasets_tts_plateformes_prod_tries_unite_Pieces)

```


# XVI) Séparation des données en 37 tables selon le type de produit

## a) Développement de la fonction pour split en 37 tables

Cette fonction prend un tableau propre data_ok avec une colonne nom_produit et renvoie une liste de sous-tableaux, un pour chaque produit distinct. Si la colonne nom_produit n’existe pas, la fonction renvoie une erreur.

```{r}
split_data_ok_par_produit <- function(data_ok) {
  # Vérifie que la colonne 'nom_produit' existe bien dans le data frame
  if (!"nom_produit" %in% colnames(data_ok)) {
    stop("La colonne 'nom_produit' est absente de data_ok")  # Arrête et affiche une erreur si la colonne manque
  }

  # Sépare le data frame en une liste de data frames, chaque sous-table correspondant à un produit unique
  liste_data_par_produit <- split(data_ok, data_ok$nom_produit)

  # Retourne cette liste de data frames
  return(liste_data_par_produit)
}


```

## b) Application de la fonction

On teste la fonction de découpage sur l’ensemble des données triées. Ensuite, on récupère les données liées uniquement au produit "tomate". Enfin, on affiche la liste des colonnes du sous-ensemble "tomate".

```{r}
# Test de la fonction split_data_ok_par_produit sur le data frame global trié
liste_tables_37_produit_bruts <- split_data_ok_par_produit(datasets_tts_plateformes_prod_tries)

```



```{r}

# Extraire le sous-dataframe correspondant au produit "asperge"
data_asperge <- liste_tables_37_produit_bruts[["asperge"]]

```

# XVII) Indicateur de pureté pour les produits triés

Cette fonction compte pour chaque produit standardisé combien de noms bruts (productName) lui correspondent, en évitant les chevauchements. Elle utilise une logique de priorité (plus long d’abord) pour attribuer les noms. Cela permet de calculer un indicateur de « pureté » des correspondances produits dans les données nettoyées.

```{r}

# Extraction des valeurs uniques de la colonne productName (noms bruts des produits)
levels_productName <- unique(datasets_tts_plateformes_prod_tries$productName)

# Extraction des valeurs uniques de la colonne nom_produit (noms produits standardisés)
levels_nom_produit <- unique(datasets_tts_plateformes_prod_tries$nom_produit)


# Fonction pour compter combien de noms bruts correspondent exclusivement à chaque produit standardisé
compter_occurrences_exclusives <- function(df, col_productName = "productName", col_nom_produit = "nom_produit") {
  
  # Étape 1 : récupérer tous les noms produits standardisés uniques, triés du plus long au plus court
  # Cela donne la priorité aux noms plus spécifiques lors de la recherche par motifs
  levels_nom_produit <- unique(df[[col_nom_produit]])
  levels_nom_produit <- levels_nom_produit[order(nchar(levels_nom_produit), decreasing = TRUE)]
  
  # Étape 2 : récupérer tous les noms bruts uniques (productName)
  all_product_names <- unique(df[[col_productName]])
  
  # Étape 3 : initialiser un vecteur logique pour indiquer si un nom brut a déjà été assigné à un produit
  noms_assignés <- rep(FALSE, length(all_product_names))
  names(noms_assignés) <- all_product_names
  
  # Étape 4 : pour chaque produit standardisé, compter les occurrences des noms bruts correspondants
  resultats <- map(levels_nom_produit, function(nom_produit) {
    
    # Créer un motif regex à partir des mots du nom produit, en gérant pluriels (s ou x) et séparateurs (espace ou tiret)
    mots <- str_split(nom_produit, " ")[[1]]
    mots_regex <- paste0("(", mots, ")(s|x)?")
    motif <- paste(mots_regex, collapse = "[- ]?")
    
    # Sélectionner uniquement les noms bruts encore non assignés
    names_disponibles <- all_product_names[!noms_assignés]
    
    # Compter le nombre d’occurrences du motif dans les noms disponibles (insensible à la casse)
    nb_occ <- str_count(tolower(names_disponibles), regex(motif, ignore_case = TRUE))
    
    # Sélectionner les noms bruts qui correspondent au motif
    matched_names <- names_disponibles[nb_occ > 0]
    matched_counts <- nb_occ[nb_occ > 0]
    
    # Marquer ces noms comme assignés pour éviter les doublons dans les prochains produits
    noms_assignés[matched_names] <<- TRUE
    
    # Retourner un tibble avec les noms bruts et le nombre d’occurrences pour ce produit
    tibble(
      !!paste0("levels_", str_replace_all(nom_produit, " ", "_")) := matched_names,
      !!paste0("nb_occurrence_", str_replace_all(nom_produit, " ", "_")) := matched_counts
    )
  }) |> set_names(levels_nom_produit)  # Nommer chaque élément de la liste par le produit correspondant
  
  return(resultats)
}


# Test de la fonction avec les listes extraites des données consolidées
liste_table_indi_purete_prod_trie <- compter_occurrences_exclusives(datasets_tts_plateformes_prod_tries)

```


# XVIII) Ajouter une colonne type de produit plus fin à un jeu de données

## a) La fonction

```{r}

ajouter_types_fin_produit <- function(df, col="productName", types_fin, autre_type = "classique") {
  require(stringr)
  
  # Fonction de nettoyage des noms
  clean_name <- function(x) {
    x <- tolower(x)
    x <- iconv(x, from = "UTF-8", to = "ASCII//TRANSLIT")
    x <- gsub("[^a-z0-9 ]", " ", x)
    x <- gsub("\\s+", " ", x)
    trimws(x) 
  }
  
  # Récupérer les levels de la colonne productName
  noms_prod_df <- factor(df[[col]])
  noms_prod_df_uniques <- levels(noms_prod_df)            

  # Nettoyer les niveaux
  noms_prod_df_uniques_clean <- sapply(noms_prod_df_uniques, clean_name)
  
  # Initialiser un vecteur de labels pour les niveaux, rempli par défaut
  labels_fin <- rep(autre_type, length(noms_prod_df_uniques))
  
  
  # Pour chaque type, on attribue ce label aux niveaux correspondants
  for (type in types_fin) {
    indices <- str_detect(noms_prod_df_uniques_clean, regex(tolower(type), ignore_case = TRUE))
    labels_fin[indices] <- type
  }
  
  df$type_fin_produit <- labels_fin[as.integer(noms_prod_df)]
  
  return(df)
}

```

## b) Definir les types fin

```{r}
types_fin_prod = c("Cerise", "Cocktail")
```


## c) Appliquer la fonction

```{r}

liste_tables_37_produit_bruts$tomate <- ajouter_types_fin_produit(liste_tables_37_produit_bruts$tomate, col="productName", types_fin_prod, autre_type = "Classique")

```




# ------------- Génération des prompts -------------

# I) Charger et permuter des levels

```{r}

liste_levels_37_produit <- lapply(liste_tables_37_produit_bruts, function(x){data.frame("nom_produit" = x$nom_produit[1],"levels" = sample(levels(factor(x$productName))))} )

```

# II) Générer les prompts

## a) Développement de la fonction

```{r}
# On génère les prompts et on applique Gemma dessus
detecter_levels_prod_transfor <- function(liste_levels, taille_chunck) {
  
  nom_prod <- liste_levels$nom_produit[1]
  
  total_levels <- length(liste_levels$levels)
  nb_chunck <- floor(total_levels/taille_chunck) + 1

  # Création des chunks de taille `taille_chunck` avec gestion du dernier chunk partiel
  chunks <- split(liste_levels$levels, ceiling(seq_along(liste_levels$levels) / taille_chunck))

  # Nombre total de chunks générés
  total_chunks <- length(chunks)

  # Limiter au nb_chunck demandé, mais sans dÃ©passer ceux disponibles
  chunks <- chunks[1:min(nb_chunck, total_chunks)]

  # Prompt de base (dynamique en fonction du produit)
base_prompt <- paste0(
  "Tu es un expert en alimentation et en classification des produits alimentaires.",
  "Tu reçois une liste de produits à base de ", nom_prod, ". ", 
  "Ta tâche est d’**identifier uniquement les produits transformés** dans cette liste.",
  "---",
  "### \uD83D\uDD36 Définition d’un **produit transformé** :",
  "Un produit est considéré comme **transformé** s’il remplit **au moins un** des critères suivants :",
  "- Il contient **d’autres ingrédients en plus de la ", nom_prod, "** (par exemple : chou, vinaigrette, gingembre, panais, quinoa, etc.)",
  "- Il a subi une **transformation culinaire** (ex. cuit, râpé, assaisonné, mixé, fermenté, stérilisé…)",
  "- Il est présenté ou conditionné comme un **plat préparé** (ex. soupe, purée, tartinade, chips, coleslaw, conserve, plat cuisiné, bocal, barquette, bouteille…)",
  "- Il est destiné à un **usage spécifique** (ex. apéritif, snacking, bébé, mix de crudités, etc.)",
  "---",
  "### ⛔ À l’inverse, un **produit brut** est **non transformé** :",
  "Tu dois **ignorer tous les produits bruts**, même s’ils sont variés ou bio.",  
  "Un produit est brut s’il :",
  "- est uniquement composé de **", nom_prod, "**, sans aucun autre ingrédient",
  "- est présenté sous forme **naturelle** : entière, en botte, en vrac, en sac, lavée ou non, bio ou non, orange, jaune, violette, de différentes variétés",
  "- n’a **subi aucune transformation culinaire**",
  "- ne contient **aucune mention de préparation, de mélange ou de conditionnement culinaire**",
  "\uD83D\uDC49 Exemples de produits **bruts à ignorer** :  ",
  paste0(nom_prod, ", ", nom_prod, " vrac, ", nom_prod, " lavées, ", nom_prod, " bio, ", nom_prod, " en botte, ", nom_prod, " jaune, ", nom_prod, " non lavées, etc."),
  "---",
  "### \uD83D\uDCE4 Ce que tu dois faire :",
  "- **Retourne uniquement** les **noms exacts** des produits transformés de la liste, **copiés tels quels**",
  "- N’ajoute **aucune explication, aucun commentaire**",
  "- Rends la sortie **exclusivement** au format R suivant :",
  "c(\"produit transformé\", \"produit transformé\", \"produit transformé\")",
  "Voici la liste de produits à analyser :"
)



  # Générer les prompts complets en y incorporant les levels
  prompts <- lapply(chunks, function(chunk) {
    paste0(base_prompt,paste(chunk, collapse = "\n"))
    
  })

  # Générer les produits transformés en appelant Gemma3 pour chaque prompt
  # resultats <- lapply(prompts, function(p) {
  #   generate("gemma3", p, stream = FALSE, output = "text")
  # })

  # Résultats des prompts et de Gemma 3
  #return(list(prompts = prompts, resultats = resultats))
  
  # Résultats des prompts
  return(prompts = prompts)
}
```


## b) Application de la fonction 

```{r}
###### On génère les prompts de taille 60 pour les 37 produits

liste_prompts_37_produit <- lapply(liste_levels_37_produit, function(x) {detecter_levels_prod_transfor(liste_levels = x, taille_chunck = 60)})


```

# III) Trouver les produits transformés avec ollamar

## a) Fonction pour les requêtes

```{r}

requete_ollama <- function(prompts){
  start_time <- Sys.time()
  
  # Application avec barre de progression
  res <- pblapply(prompts, function(prompt) {
  generate("llama3.1", prompt, stream = FALSE, output = "text")
    })
  
  # Timer de fin
  end_time <- Sys.time()
  print(end_time - start_time)
  
  return (res)
}

```


## b) Choisir des produits

```{r}

prod_select <- c("abricot", "asperge")

liste_prompts_produits_select <- liste_prompts_37_produit[prod_select]

```


## c) Application de la fonction

```{r}

liste_res_llm <- lapply(liste_prompts_produits_select, function(x) {requete_ollama(x)})

```


# ------- Traitement des réponses du modèle de langage -------


# I) Extraction des résultats (noms des produits transformés) renvoyé par le modèle de langage

```{r}
# Fonction permettant d'extraire une liste de produits transformés depuis un texte généré par un LLM

extraire_liste_produits <- function(texte_source) {
  # Étape 1 : Remplace les appels à 'C(' par 'c(' (R est sensible à la casse, 'C(' pourrait causer une erreur)
  texte_source <- gsub("C\\(", "c(", texte_source, ignore.case = TRUE)

  # Étape 2 : Supprime les sauts de ligne pour éviter de casser la chaîne de caractères lors de l'évaluation
  texte_source <- gsub("\n", " ", texte_source)

  # Étape 3 : Définit le motif (regex) pour détecter un appel à la fonction R c(...) contenant une liste de chaînes
  motif_vecteur <- "c\\s*\\((.*?)\\)"

  # Étape 4 : Cherche la première correspondance avec le motif défini ci-dessus
  correspondance_vecteur <- regmatches(texte_source, regexpr(motif_vecteur, texte_source, perl = TRUE))

  # Étape 5 : Si une correspondance a été trouvée et qu’elle n’est pas vide, tenter de l’évaluer comme du code R
  if (length(correspondance_vecteur) > 0 && correspondance_vecteur != "") {
    tentative_evaluation <- tryCatch(
      eval(parse(text = correspondance_vecteur)),  # Essaie d'exécuter le texte comme du code R
      error = function(e) NULL  # En cas d'erreur, retourne NULL
    )

    # Étape 6 : Si l’évaluation a réussi et retourne un vecteur de chaînes de caractères, le retourner
    if (!is.null(tentative_evaluation) && is.character(tentative_evaluation)) {
      return(tentative_evaluation)
    }
  }

  # Étape 7 : Si aucun vecteur c(...) exploitable n’a été trouvé, chercher manuellement des chaînes entre guillemets
  positions_chaines <- gregexpr('"([^"]{2,100})"', texte_source, perl = TRUE)
  chaines_trouvees <- regmatches(texte_source, positions_chaines)[[1]]

  # Étape 8 : Si au moins deux chaînes sont extraites, les retourner comme vecteur après nettoyage
  if (length(chaines_trouvees) >= 2) {
    return(trimws(gsub('"', "", chaines_trouvees)))  # Supprime les guillemets et espaces superflus
  }

  # Étape 9 : Vérifie si le texte ressemble à une liste (éléments précédés de * ou -)
  if (grepl("\\*\\s+", texte_source) || grepl("-\\s+", texte_source)) {
    lignes_separees <- unlist(strsplit(texte_source, "\n"))  # Découpe le texte ligne par ligne
    lignes_avec_puce <- grep("^\\s*(\\*|-)", lignes_separees, value = TRUE)  # Ne garde que les lignes avec puces

    if (length(lignes_avec_puce) > 0) {
      return(trimws(gsub("^(\\*|-)+\\s*", "", lignes_avec_puce)))  # Supprime les puces et espaces initiaux
    }
  }

  # Étape 10 : Si aucune méthode n’a permis d’extraire une liste, retourner NULL
  return(NULL)
}

```


# II) Comparaison des produits listés dans les prompts avec ceux extraits par LLM

```{r}
comparer_listes_produits <- function(prompts_attendus, reponses_llm, verite_terrain=NULL) {
  
  # Étape 1 : Extraction des produits attendus depuis les prompts (niveau "level")
  produits_attendus <- lapply(prompts_attendus, function(texte_prompt) {
    # Extrait tout ce qui suit "Voici la liste de produits à analyser :"
    texte_extrait <- str_extract(
      texte_prompt,
      "(?s)(?<=Voici la liste de produits à analyser :)\\s*.*"
    )
    # Découpe le texte extrait ligne par ligne
    unlist(strsplit(texte_extrait, "\n"))
  })
  
  # Étape 2 : Extraction des produits reconnus par le LLM (via la fonction extraire_liste_produits defini plus haut)
  produits_extraits_llm <- lapply(reponses_llm, function(texte_reponse) {
    extraire_liste_produits(texte_reponse)
  })
  
  # Fonctionpour remplacer les caractères spéciaux regex
  remplacer_caract_speci_regex <- function(x) {
    stringr::str_replace_all(x, "([\\^$.|?*+()\\[\\]{}])", "\\\\\\1")
  }
  
    # Fonction pour nettoyer les noms
  clean_name <- function(x) {
    stringr::str_replace_all(x, "[^a-zA-Z0-9 ]", "")
    }

  # Étape 3 : Comparaison entre les produits attendus et extraits
  comparaison <- lapply(seq_along(produits_attendus), function(i) {
    liste_attendue <- produits_attendus[[i]]
    liste_extraite <- produits_extraits_llm[[i]]
    
    # Identifie les produits présents dans les deux listes (correspondance exacte)
    produits_communs <- intersect(liste_attendue, liste_extraite)
    
    # Identifie les "hallucinations" brutes ou pseudo_hallucinations : produits extraits par le LLM mais absents de la liste initiale 
    pseudo_hallucinations <- setdiff(liste_extraite, liste_attendue)
    
    # Identifie les hallucinations réelles : toutes les pseudo_hallucinations qui ne sont pas des nom de produits mal écrits par le modèle, c'est ceux qu'il a inventé
    # Pour cela on construit une expression régulière avec chaque mot ou élément du nom de produit renvoyé par le modèle () et on va recherché si il y existe des vrai noms de produits qui sont composé de l'intégralité de ces mots, si non alors on considère que ces noms de produit ont été inventé par le modèle (hallucinations_reelles)

    hallucinations_reelles <- pseudo_hallucinations[!sapply(pseudo_hallucinations, function(h) {
      #  on nettoie le nom du produits et on le découpe à partir des espaces
      mots <- strsplit(tolower(clean_name(h)), "\\s+")[[1]] 
      mots <- remplacer_caract_speci_regex(mots)
      
      if (length(mots) == 0) return(FALSE)  # cas vide (pas de hallucination)
      
      # construction du regex : .*mot1.*mot2.*mot3.*
      pattern <- paste0(".*", paste(mots, collapse = ".*"), ".*")
      any(grepl(pattern, tolower(clean_name(liste_attendue))))
    })]
    
    # on retir les vrais hallucinations des pseudo_hallucinations (vrai nom de produit mal écrit)
    pseudo_hallucinations <- setdiff(pseudo_hallucinations, hallucinations_reelles)
    
    # on va rechercher la vrai écriture des pseudo_hallucinations pour corriger l'orthographe des réponses du modèle
    hallucinations_corrige <- unlist(lapply(pseudo_hallucinations, function(h) {
  mots <- strsplit(tolower(clean_name(h)), "\\s+")[[1]]
  mots <- remplacer_caract_speci_regex(mots)
  if (length(mots) == 0) return(NULL) 
  
  pattern <- paste0(".*", paste(mots, collapse = ".*"), ".*")
  
  # on récupère les vrais noms de produit qui match avec l'expression régulière
  vrais_noms <- liste_attendue[sapply(liste_attendue, function(p) {
    grepl(pattern, tolower(clean_name(p)))
  })]
  
  if (length(vrais_noms) == 0) return(NULL) # Cas vide
  
  # Si un seul match, on le retourne directement
  if (length(vrais_noms) == 1) return(vrais_noms)
  
  # Sinon il y a plusieurs noms de produit, dans ce cas on va chercher à retourner le vrai nom de produit qui est le plus proche de celui renvoyé par le modèle 
  
  # rechercher une correspondance exacte (en minuscule)
  nom_llm <- tolower(h)
  correspondance_exacte <- vrais_noms[tolower(vrais_noms) == nom_llm]
  
  if (length(correspondance_exacte) == 1) {
    return(correspondance_exacte)
  } else {
    # On choisit celui avec la plus petite distance de Levenshtein (vrai nom de produit qui est le plus proche de celui renvoyé par le modèle)
    distances <- stringdist(nom_llm, tolower(vrais_noms), method = "lv")
    meilleur_nom <- vrais_noms[which.min(distances)]
    return(meilleur_nom)
  }
}))
    # vérifier qu'on a bien des levels uniques
    hallucinations_corrige <- unique(hallucinations_corrige)
    
    # On corrige les réponses du modèle en rajoutant les vrais noms de produit dans les Levels communs s’ils n’existent pas déjà (unique)
    produits_communs <- unique(c(produits_communs, hallucinations_corrige))
    
    # Si on a une vérité terrain
    if (!is.null(verite_terrain)){
      # On récupère les vrais noms des produits transformés selon la vérité terrain, étiqueté avec "1" dans la colonne Prod_transfo_ou_non
      verite_terrain_produit_transfo <- verite_terrain$levels_asperge[verite_terrain$Prod_transfo_ou_non == "1"]
      
      # On récupère parmi les vrais noms des produits ceux qui sont des produits transformés (les produits transformés attendus)
      prod_transfo_levels_initiaux <- intersect(verite_terrain_produit_transfo, liste_attendue)
      
      # On peut ainsi avoir les noms des produits transformés trouvé par le llm
      produit_transfo_llm <- intersect(prod_transfo_levels_initiaux, produits_communs)
      
      # On en déduit les noms des produits transformés pas trouvé par le llm
      prod_transfo_pas_trouver <- setdiff(prod_transfo_levels_initiaux, produit_transfo_llm)
    } else{
      prod_transfo_levels_initiaux <- NA
      produit_transfo_llm <- produits_communs
      prod_transfo_pas_trouver <- NA
    }
    
    
    # Structure des résultats par comparaison
    list(
      levels_initiaux = liste_attendue,
      levels_llm = liste_extraite,
      fausses_hallucina = pseudo_hallucinations,
      vraies_hallucina = hallucinations_reelles,
      levels_communs = produits_communs,
      prod_transfo_attendus = prod_transfo_levels_initiaux,
      produit_transfo_llm = produit_transfo_llm,
      prod_transfo_pas_trouver = prod_transfo_pas_trouver
    )
  })
  
  # Étape 4 : Retourne la liste complète des résultats de comparaison
  return(comparaison)
}
```

# III) Tableau d'indicateur de pureté 

```{r}
# fonction pour construire le tableau d'indicateur
table_indicateurs_purete <- function(resultats_comparaison){
  
  # On initialise le tableau d'indicateur de pureté 
  table_indica_purete <- data.frame(
    chunck_traite = c(1:length(resultats_comparaison)),
    nb_levels_initial = NA,
    nb_levels_llm = NA,
    nb_levels_commun = NA,
    nb_fausses_halluci_llm = NA,
    nb_vraies_halluci_llm = NA,
    nb_prod_attendus = NA, 
    nb_prod_transfo_trouves_llm = NA,
    nb_prod_transfo_pas_trouves_llm = NA,
    nb_prod_llm_st_prod_bruts = NA)

  # On remplit la colonne du nb_levels_initial
  table_indica_purete$nb_levels_initial <- sapply(resultats_comparaison, function(x) length(x$levels_initiaux))
  
  # On remplit la colonne du nb_levels_llm
  table_indica_purete$nb_levels_llm <- sapply(resultats_comparaison, function(x) length(x$levels_llm))

  # On remplit la colonne du nb_levels_commun
  table_indica_purete$nb_levels_commun <- sapply(resultats_comparaison, function(x) length(x$levels_communs))
  
  # On remplit la colonne du nb_fausses_halluci_llm
  table_indica_purete$nb_fausses_halluci_llm <- sapply(resultats_comparaison, function(x) length(x$fausses_hallucina))
  
  # On remplit la colonne du nb_vraies_halluci_llm
  table_indica_purete$nb_vraies_halluci_llm <- sapply(resultats_comparaison, function(x) length(x$vraies_hallucina))
  
  # On remplit la colonne du nb_prod_attendus
  table_indica_purete$nb_prod_attendus <- if(!any(is.na(resultats_comparaison[[1]]$prod_transfo_attendus))){sapply(resultats_comparaison, function(x) length(x$prod_transfo_attendus))}
  
  # On remplit la colonne du nb_prod_transfo_trouves_llm
  table_indica_purete$nb_prod_transfo_trouves_llm <- sapply(resultats_comparaison, function(x) length(x$produit_transfo_llm))
  
  # On remplit la colonne du nb_prod_transfo_pas_trouves_llm
  table_indica_purete$nb_prod_transfo_pas_trouves_llm <- if(!any(is.na(resultats_comparaison[[1]]$prod_transfo_pas_trouver))){sapply(resultats_comparaison, function(x) length(x$prod_transfo_pas_trouver))}
  
  # On remplit la colonne du nombre de produit llm qui sont des produits bruts
  table_indica_purete$nb_prod_llm_st_prod_bruts <- if(!any(is.na(resultats_comparaison[[1]]$prod_transfo_pas_trouver))){sapply(resultats_comparaison, function(x) (length(x$levels_communs) - length(x$produit_transfo_llm)))}
  
  
  
  ### Calcul des moyennes et totaux
  
  # Selectionner les noms des colonnes en retirant la colonne "chunck_traite" 
  cols_to_sum <- names(table_indica_purete)[-1]
  
  # Calcul des totaux et moyennes par colonne
  totaux <- colSums(table_indica_purete[, cols_to_sum], na.rm = TRUE)
  moyennes <- colMeans(table_indica_purete[, cols_to_sum], na.rm = TRUE)
  
  # Création des lignes à ajouter (ligne Total et Moyenne) et ajout de la colonne "chunck_traite"
  ligne_total <- c(chunck_traite = "Total", round(totaux))
  ligne_moyenne <- c(chunck_traite = "Moyenne", round(moyennes))
  
  # Ajout au tableau 
  table_indica_purete <- rbind( 
    table_indica_purete, ligne_total, ligne_moyenne)
  
  # Reconversion des colonnes sauf 'chunck_traite' en numérique
  table_indica_purete[cols_to_sum] <- lapply(table_indica_purete[cols_to_sum], as.numeric)
  
  # On remplace la moyenne de levels_initial par un NA car ça n'a pas de sens
  table_indica_purete[length(resultats_comparaison)+2,2] <- NA
  
  return(table_indica_purete)
}


```

# IV) Matrice de confiusion 

```{r}
# Fonction pour créer la matrice de confusion 
matrice_confusion <- function(table_indica_purete, resultats_comparaison){
  # Créer une matrice de confusion vide avec des noms de colonnes
  matrice_confusion_prompt <- data.frame(
      Positifs = c(NA, NA),
      Negatifs = c(NA, NA),
      row.names = c("Positifs_llm", "Negatifs_llm"))
  
  if("prod_transfo_attendus" %in% colnames(table_indica_purete)){
    return(matrice_confusion_prompt)
  }else{
    ###### On remplit la matrice de confusion
    table_indica_purete$nb_prod_transfo_trouves_llm[[length(resultats_comparaison)+1]]
  
    # Etape 1 : Vrais positifs : Les produits transformés trouvés par le llm qui sont des produits transformés 
    matrice_confusion_prompt$Positifs[[1]] <- table_indica_purete$nb_prod_transfo_trouves_llm[[length(resultats_comparaison)+1]]
    
    # Etape 2 : Faux positifs : Les produits transformés trouvés par le llm qui sont des produits bruts
    matrice_confusion_prompt$Negatifs[[1]] <- table_indica_purete$nb_levels_commun[[length(resultats_comparaison)+1]] - table_indica_purete$nb_prod_transfo_trouves_llm[[length(resultats_comparaison)+1]]
    
    # Etape 3 : Vrais négatifs : Les produits bruts trouvés par le llm qui sont des produits bruts 
    matrice_confusion_prompt$Negatifs[[2]] <- table_indica_purete$nb_levels_initial[length(resultats_comparaison)+1] - table_indica_purete$nb_levels_commun[[length(resultats_comparaison)+1]] - table_indica_purete$nb_prod_transfo_pas_trouves_llm[[length(resultats_comparaison)+1]]
    
    # Etape 4 : Faux négatifs : Les produits bruts trouvés par le llm qui sont des produits transformés 
    matrice_confusion_prompt$Positifs[[2]] <-table_indica_purete$nb_prod_transfo_pas_trouves_llm[[length(resultats_comparaison)+1]]
    
    return(matrice_confusion_prompt)
  }
}
```

# V) Suppresion des levels de produits transformés dans le jeu de données

```{r}
# Fonction de suppresion des levels de produits transformés
retirer_prod_transfo <- function(data, res_comparaison, stat=TRUE){
  
  # Récupérer toute las liste des produits transformés trouvés par le llm
  liste_prod_transfo_llm <- unlist(lapply(res_comparaison, function(x) x$produit_transfo_llm))
  
  # On vérifie que les levels de produits transformés sont bien uniques
liste_prod_transfo_llm <- unique(liste_prod_transfo_llm)

  # On supprime les produits transformés pour le jeu de données des asperges 
  data_bruts <- data[!(data$productName %in% liste_prod_transfo_llm), ]
  
  # Détails
  if (stat) {
    nb_prod_ini <- length(data$productName)
    nb_levels_ini <- length(levels(factor(data$productName)))
  
    nb_levels_retire <- length(liste_prod_transfo_llm)
  
    nb_prod_fin <- length(data_bruts$productName)
    nb_levels_fin <- length(levels(factor(data_bruts$productName)))
    
    cat("Nombre de produits initial", data$nom_produit[1], ": ", nb_prod_ini, "levels: ", nb_levels_ini, "\n")
    cat("Nombre de produits retirés", data$nom_produit[1], ": ", nb_prod_ini - nb_prod_fin, "levels: ", nb_levels_retire, "\n")
    cat("Nombre de produits final", data$nom_produit[1], ": ", nb_prod_fin, "levels: ", nb_levels_fin, "\n")
    
  }
  
  return(data_bruts)
}
```



# VI) Résultats

####  Vérification de l'extraction des résultats du LLM dans une liste

```{r}
verifi_LLM_res <- lapply(liste_res_llm, function(x) lapply(x, extraire_liste_produits))

which(sapply(verifi_LLM_res, function(x) {sapply(x, is.null)}))

```

####  Résutats de la comparaison

Si on sélectionner un seul produit, ou si on veut choisir un parmi ceux sélectionné

```{r}
# Exécution de la fonction pour un seul prompt choisi ou pour plusieurs prompts
resultats_comparaison <- mapply(comparer_listes_produits, 
                                liste_prompts_produits_select, 
                                liste_res_llm, SIMPLIFY = FALSE)
```



```{r}
### Voir la liste des vrais produits transformés trouver par le modèle

produit_transfo_llm <- (lapply(resultats_comparaison, function(x) {lapply(x, function(y) y$levels_communs)}))

```

####  Tableau d'indicateurs

```{r}
table_indicateurs <- lapply(resultats_comparaison, function(x) { table_indicateurs_purete(x)})

view(table_indicateurs)
```

####  Matrice de confusion

```{r}
# Pas encore au points
mat_confusion <- lapply(resultats_comparaison, function(x) { matrice_confusion(table_indicateurs$x, x)})

view(mat_confusion)

```

### Suppresion des levels de produits transformés dans le jeu de données

```{r}
# récupérer les données sélectionnées
data_tt <- liste_tables_37_produit_bruts[prod_select]

#Suppresion des levels de produits transformés
data_bruts <- mapply(
  FUN = retirer_prod_transfo,
  data_tt,
  resultats_comparaison[names(data_tt)],
  SIMPLIFY = FALSE
)

```

# VII) Exportations

### Exportation des jeux de données bruts

```{r}
# Créer le dossier "data_bruts" s'il n'existe pas
dir.create("data_bruts", showWarnings = FALSE)

purrr::iwalk(data_bruts, function(df, nom) {
  nom_fichier <- paste0("data_", nom, "_bruts.xlsx")
  path_fichier <- file.path("data_bruts", paste0("data_", nom, "_bruts.xlsx"))
  write_xlsx(df, path_fichier)
  cat(nom_fichier, " sauvegarder! ", "\n")
  })

```
